{"cells":[{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:45.666813Z","start_time":"2020-02-27T12:53:44.670194Z"},"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nfrom PIL import Image\nimport six\n\nimport random\nimport time\nimport os\nimport gc\nfrom tqdm import tqdm\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:45.976090Z","start_time":"2020-02-27T12:53:45.667807Z"},"trusted":true},"cell_type":"code","source":"import torch\nimport torchvision","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TODO:\n* [x] Load data from dataset 128\n* [x] Implement SEResNeXt training through clean pytorch\n* [ ] add loss and metric logging for all 3 groups\n* [ ] Add CutMix or mixup/cutmix 1:1\n* [ ] Running average weights\n* [ ] Add more layers after backbone\n* [ ] 100-150 epochs\n \nTODO if have time:\n* [ ] Think about: https://www.kaggle.com/c/bengaliai-cv19/discussion/130503\n* [ ] Try AdamW\n* [ ] Add MixUp\n* [ ] Add other augmentations\n* [ ] Add Cosine LR\n* [ ] Try different models (se_resnet101, Densenet121)\n"},{"metadata":{},"cell_type":"markdown","source":"```\n> 39 place\nModel: Densenet121\nimg_size: 3x224x224 (simple resize)\nAugmentation: NOT cutmix or mixup\nEpoch: 40 (still running)\nCV: 0.9938\nLB: 0.9825\n```\n\n```\n> 11 place\nmodel: se-resnext50\nimg_size: 3x137x236\naugmentation: rotate, cutmix\nEpoch: 80\nCV : 0.994\nLB: 0.985\n\nI can not get the CV score more than 0.997 from some top kagglers. So perhaps I can get some advice and help from your guys hereüòÉ \n```\n\n```\nModel: se-resnext50-32x4d\nImage size: 128x128x1\nI combined augmentation methods and Cutmix is one of them\n150 epochs\nCV: 0.9937\nLB: 0.9838\n\nMy CV : 0.5 * 0.99107(root) + 0.25 * 0.99648(vowel) + 0.25 * 0.99641(consonant) = 0.9937\n```\n\n```\nmodel: se_resnext50_32x4d\nimgsize: 128x128\nsplit: 5/6 train, 1/6 valid\ninference: 15 minutes (kaggle kernels)\nno tta, no ensemble\n```"},{"metadata":{},"cell_type":"markdown","source":"```\nI had another post asking people what kind of input size they use and a few people were surprised at the score I got with 64x64x1 inputs. So I decided to shared the strategy a little bit because using 64x64 is nice for people with low computing power (I only have 2x2080).\nThe strategy is as follows:\nSingle model of wide resnet with three dense layers on top (One for each class)\nDropout before each pooling layer\nI used only cutout and trained for 100 epochs.\nScores:\n0.97 with 0.15 validation split\n0.9718 without validation\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/pytorch-pretrained-models/repository/pretrained-models.pytorch-master/ > /dev/null # no output","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:45.980997Z","start_time":"2020-02-27T12:53:45.977979Z"},"trusted":true},"cell_type":"code","source":"SEED = 1984\nBATCH_SIZE = 128  # 128\nNUM_EPOCHS = 50\nMODEL_NAME = 'se_resnext50_32x4d'  #  'se_resnext50_32x4d'  'se_resnext101_32x4d'  # 'wide_resnet50_2'\n\nOUT_PATH = '.'\nTRAIN = '../input/bengali-crop-128x128/'\nLABELS = '../input/bengaliai-cv19/train.csv'\n\n# TRAIN = '../input/train/'\n# LABELS = '../input/train.csv'","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:45.991941Z","start_time":"2020-02-27T12:53:45.982965Z"},"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Custom DataSet"},{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:46.000945Z","start_time":"2020-02-27T12:53:45.993959Z"},"trusted":true},"cell_type":"code","source":"class BengaliAIDataset(torch.utils.data.Dataset):\n    def __init__(self, images_path, labels, transform=None):\n        self.images_path = images_path\n        self.transform = transform\n        \n        self.labels = labels\n        self.image_names = self.labels[:, 0] + '.png'\n        self.targets = self.labels[:, 1:4].astype(np.uint8)\n    \n    def __len__(self):\n        \"\"\"return length of this dataset\"\"\"\n        return len(self.labels)        \n    \n    def get_image(self, image_name):\n        \"\"\"\n        gets a image by a name gathered from file list text file\n        :param name: name of targeted image\n        :return: an image\n        \"\"\"\n        image_path = os.path.join(self.images_path, image_name)\n        image = Image.open(image_path)\n#         image = cv2.imread(image_path, 0)\n        return image\n    \n    def __getitem__(self, index):\n        image_name = self.image_names[index]\n        image = self.get_image(image_name)\n        \n        if self.transform:\n            image = self.transform(image)\n            \n        target = torch.from_numpy(self.targets[index])\n        \n        return (image, target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image transformations"},{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:46.005932Z","start_time":"2020-02-27T12:53:46.001914Z"},"trusted":true},"cell_type":"code","source":"train_transform = torchvision.transforms.Compose([\n                torchvision.transforms.ToTensor(),\n                torchvision.transforms.Normalize((0.0528,), (0.1629,))]) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create train dataset with transformations"},{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:46.849800Z","start_time":"2020-02-27T12:53:46.006900Z"},"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nlabels = pd.read_csv(LABELS).to_numpy()\n\nlabels_train, labels_val = train_test_split(labels, test_size=0.15, stratify=labels[:, 1])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:46.854734Z","start_time":"2020-02-27T12:53:46.850745Z"},"trusted":true},"cell_type":"code","source":"train_dataset = BengaliAIDataset(images_path=TRAIN, labels=labels_train, transform=train_transform)\nval_dataset = BengaliAIDataset(images_path=TRAIN, labels=labels_val, transform=train_transform)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create dataloader from train_dataset"},{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:46.861741Z","start_time":"2020-02-27T12:53:46.856729Z"},"trusted":true},"cell_type":"code","source":"loader_train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\nloader_val = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n\ndataloaders = {'train': loader_train, 'val': loader_val}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check loader"},{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:47.671549Z","start_time":"2020-02-27T12:53:46.863711Z"},"trusted":true},"cell_type":"code","source":"nrow, ncol = 3, 3\n\nfig, axes = plt.subplots(nrow, ncol, figsize=(6, 6))\naxes = axes.flatten()\n\nfor i, ax in enumerate(axes):\n    image, label = train_dataset[i]\n    ax.imshow(image.reshape((128, 128)), cmap='Greys')\n    ax.set_title(f'label: {label.data.tolist()}')\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:48.442598Z","start_time":"2020-02-27T12:53:47.673544Z"},"trusted":true},"cell_type":"code","source":"import pretrainedmodels\nfrom torch import nn\nimport torch.nn.functional as F\n\nimport copy\nfrom sklearn.metrics import recall_score","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:48.473405Z","start_time":"2020-02-27T12:53:48.467421Z"},"trusted":true},"cell_type":"code","source":"class Loss_combine(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n    def forward(self, y_pred, target, reduction='mean'):\n        y_pred1, y_pred2, y_pred3 = torch.split(y_pred, [n_grapheme, n_vowel, n_consonant], dim=1)\n        y_pred1, y_pred2, y_pred3 = y_pred1.float(), y_pred2.float(), y_pred3.float()\n        y = target.long()\n        return 0.7 * F.cross_entropy(y_pred1, y[:,0], reduction=reduction) + \\\n               0.1 * F.cross_entropy(y_pred2, y[:,1], reduction=reduction) + \\\n               0.2 * F.cross_entropy(y_pred3, y[:,2], reduction=reduction)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:48.487366Z","start_time":"2020-02-27T12:53:48.480385Z"},"trusted":true},"cell_type":"code","source":"# def eval_metric(input_x, target):\n#     pred = torch.split(input_x, [n_grapheme, n_vowel, n_consonant], dim=1)\n    \n#     recall_grapheme = Recall(average=True)\n#     recall_vowel = Recall(average=True)\n#     recall_consonant = Recall(average=True)\n    \n#     recall_grapheme.update((pred[0], target[:, 0].long()))\n#     recall_vowel.update((pred[1], target[:, 1].long()))\n#     recall_consonant.update((pred[2], target[:, 2].long()))\n    \n#     res_grapheme = recall_grapheme.compute()\n#     res_vowel = recall_vowel.compute()\n#     res_consonant = recall_consonant.compute()\n\n#     final_score = np.average([res_grapheme, res_vowel, res_consonant], weights=[2, 1, 1])\n#     return final_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def eval_metric(y_pred, y_fact):\n    y_pred = torch.split(y_pred, [n_grapheme, n_vowel, n_consonant], dim=1)\n    pred_labels = [torch.argmax(py, dim=1).cpu().numpy() for py in y_pred]\n\n    y_fact = y_fact.cpu().numpy()\n\n    recall_grapheme = recall_score(pred_labels[0], y_fact[:, 0], average='macro', zero_division=0)\n    recall_vowel = recall_score(pred_labels[1], y_fact[:, 1], average='macro', zero_division=0)\n    recall_consonant = recall_score(pred_labels[2], y_fact[:, 2], average='macro', zero_division=0)\n    \n    scores = [recall_grapheme, recall_vowel, recall_consonant]\n    final_score = np.average(scores, weights=[2, 1, 1])\n\n    return final_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:48.511302Z","start_time":"2020-02-27T12:53:48.488363Z"},"trusted":true},"cell_type":"code","source":"def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    history = {'train_loss': list(), 'train_acc': list(), 'val_loss': list(), 'val_acc': list(), 'lr': list(), }\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n        print('-' * 10)\n        \n        current_lr = get_lr(optimizer)\n        try:\n            if current_lr < history['lr'][-1]:\n                print(\"LR reduced from {} to {}\".format(history['lr'][-1], current_lr))\n        except:\n            pass\n        history['lr'].append(current_lr)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    # Get model outputs and calculate loss\n                    # Special case for inception because in training it has an auxiliary output. In train\n                    #   mode we calculate the loss by summing the final output and the auxiliary output\n                    #   but in testing we only consider the final output.\n \n                    outputs = model(inputs)\n                    loss = criterion(outputs, labels)\n\n                    _, preds = torch.max(outputs, 1)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += eval_metric(outputs, labels)\n\n            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n            history['{}_loss'.format(phase)].append(epoch_loss)\n            history['{}_acc'.format(phase)].append(epoch_acc)\n        scheduler.step(epoch_loss)\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, history","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> –í—Å–µ–º –ø—Ä–∏–≤–µ—Ç. –ö–∞–∫ –≤—ã —Ä–∞–±–æ—Ç–∞–µ—Ç–µ —Å —Ä–∞–∑–º–µ—Ä–æ–º –∫–∞—Ä—Ç–∏–Ω–æ–∫, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ä–∞–∑–º–µ—Ä—É, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –æ–±—É—á–∞–ª–∏—Å—å —Å–µ—Ç–∫–∏? –í—ã —É–±–∏—Ä–∞–µ—Ç–µ —Å–ª–æ–∏, —á—Ç–æ–±—ã –∫–∞—Ä—Ç–∏–Ω–∫–∞ –Ω–µ —Å–≤–µ—Ä–Ω—É–ª–∞—Å—å –≤ —Ç–µ–Ω–∑–æ—Ä —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏ Height/Width –∏–∑–º–µ—Ä–µ–Ω–∏—è–º–∏? –ò–ª–∏ –µ—Å—Ç—å –±–æ–ª–µ–µ —Ö–æ—Ä–æ—à–∏–π —Å–ø–æ—Å–æ–±?\n\n> AdaptiveAvgPool –≤–º–µ—Å—Ç–æ –æ–±—ã—á–Ω–æ–≥–æ"},{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:48.520278Z","start_time":"2020-02-27T12:53:48.512301Z"},"trusted":true},"cell_type":"code","source":"def get_model(model_name='se_resnext101_32x4d', n_out=186, pretrained='imagenet'):\n    if model_name.startswith('se_resnext'):\n        model = pretrainedmodels.__dict__[model_name](pretrained=None)\n#         model = pretrainedmodels.__dict__['se_resnext101_32x4d'](pretrained=None)\n        pretrained_path = os.popen(\"find ../input/pytorch-pretrained-models -iname {}*\".format(model_name)).read().strip()\n        model.load_state_dict(torch.load(pretrained_path))\n\n        model.layer0.conv1.in_channels = 1\n        model.layer0.conv1.weight.data = model.layer0.conv1.weight.mean(dim=1, keepdim=True)\n\n        model.avg_pool = nn.AvgPool2d(kernel_size=4, stride=1)\n        model.last_linear = nn.Linear(in_features=2048, out_features=n_out, bias=True)\n    elif model_name.startswith('wide_resnet'):\n        model = torch.hub.load('pytorch/vision:v0.5.0', 'wide_resnet50_2', pretrained=True)\n        \n        model.conv1.in_channels = 1\n        model.conv1.weight.data = model.conv1.weight.mean(dim=1, keepdim=True)\n        \n        model.maxpool = nn.AdaptiveMaxPool2d((112, 112))\n        model.fc = nn.Linear(in_features=2048, out_features=n_out, bias=True)\n    else:\n        raise Exception\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_optimizer(model_name='se_resnext101_32x4d'):\n    if model_name.startswith('se_resnext'):\n        optimizer = torch.optim.Adam(\n            [\n                {\"params\": model.layer0.parameters()},\n                {\"params\": model.layer1.parameters()},\n                {\"params\": model.layer2.parameters()},\n                {\"params\": model.layer3.parameters()},\n                {\"params\": model.layer4.parameters()},\n                {\"params\": model.last_linear.parameters(), \"lr\": 0.005},\n            ],\n            lr=0.001,\n        )\n    elif model_name.startswith('wide_resnet'):\n        optimizer = torch.optim.Adam(\n            [\n                {\"params\": model.conv1.parameters()},\n                {\"params\": model.bn1.parameters()},\n                {\"params\": model.layer1.parameters()},\n                {\"params\": model.layer2.parameters()},\n                {\"params\": model.layer3.parameters()},\n                {\"params\": model.layer4.parameters()},\n                {\"params\": model.fc.parameters(), \"lr\": 0.005},\n            ],\n            lr=0.001,\n        )\n    else:\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    return optimizer","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:51.960260Z","start_time":"2020-02-27T12:53:48.522274Z"},"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nn_grapheme = 168\nn_vowel = 11\nn_consonant = 7\nn_total = n_grapheme + n_vowel + n_consonant\n\nmodel = get_model(model_name=MODEL_NAME, n_out=n_total)\nmodel = model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:51.968206Z","start_time":"2020-02-27T12:53:51.961224Z"},"trusted":true},"cell_type":"code","source":"grad_params = list()\nfor name, param in model.named_parameters():\n    if param.requires_grad == True:\n#         print(name)\n        grad_params.append(name)\nprint(\"N params:\", len(grad_params))","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:51.982195Z","start_time":"2020-02-27T12:53:51.977181Z"},"trusted":true},"cell_type":"code","source":"optimizer = get_optimizer(MODEL_NAME)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-10)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:51.987155Z","start_time":"2020-02-27T12:53:51.983165Z"},"trusted":true},"cell_type":"code","source":"criterion = Loss_combine()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:59.572161Z","start_time":"2020-02-27T12:53:51.989149Z"},"trusted":true},"cell_type":"code","source":"# Train and evaluate\nmodel, hist = train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=NUM_EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:59.591110Z","start_time":"2020-02-27T12:53:44.721Z"},"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n\naxes[0].plot(hist['train_loss'], label='train_loss');\naxes[0].plot(hist['val_loss'], label='val_loss');\n\naxes[1].plot(hist['train_acc'], label='train_acc');\naxes[1].plot(hist['val_acc'], label='val_acc');\n\naxes[2].plot(hist['lr'], label='learning rate');\n\naxes[0].set_title(\"Loss\");\naxes[1].set_title(\"Metric\");\naxes[2].set_title(\"Learning rate\");\n\naxes[0].legend();\naxes[1].legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(hist)\ndf.to_csv('./hist.csv')\ndf","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-02-27T12:53:59.591110Z","start_time":"2020-02-27T12:53:44.723Z"},"trusted":true},"cell_type":"code","source":"model_path = os.path.join(OUT_PATH, 'seresnext_v0.1.pt')\ntorch.save(model.state_dict(), model_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":4}