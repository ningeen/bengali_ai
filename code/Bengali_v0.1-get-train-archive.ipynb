{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "\n",
    "CROP_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "outdir = Path('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load images from parquet/feather depending on submit\n",
    "* crop and save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img, crop_size=CROP_SIZE):\n",
    "    return cv2.resize(img, (crop_size, crop_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(data_type='train', submission=False, indices=[0, 1, 2, 3]):\n",
    "    assert data_type in ['train', 'test']\n",
    "    \n",
    "    datadir = Path('/kaggle/input/bengaliai-cv19')\n",
    "    featherdir = Path('/kaggle/input/bengaliaicv19feather')\n",
    "    \n",
    "    if submission:\n",
    "        image_df_list = [pd.read_parquet(datadir / f'{data_type}_image_data_{i}.parquet')\n",
    "                         for i in indices]\n",
    "    else:\n",
    "        image_df_list = [pd.read_feather(featherdir / f'{data_type}_image_data_{i}.feather')\n",
    "                         for i in indices]\n",
    "\n",
    "    img_names = np.concatenate([df.iloc[:, 0] for df in image_df_list])\n",
    "    print('Read complete')\n",
    "\n",
    "    reshape_data = lambda data: 255 - data.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH).astype(np.uint8)\n",
    "    images = [reshape_data(df) for df in image_df_list]\n",
    "    \n",
    "    print('Reshape complete')\n",
    "    \n",
    "    del image_df_list\n",
    "    gc.collect()\n",
    "    \n",
    "    images = np.concatenate(images, axis=0)\n",
    "    print(f'Concatenate complete. Shape: {images.shape}')\n",
    "    return img_names, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read complete\n",
      "Reshape complete\n",
      "Concatenate complete. Shape: (200840, 137, 236)\n"
     ]
    }
   ],
   "source": [
    "img_names, images = prepare_image(data_type='train', submission=False, indices=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this to get train archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200840/200840 [04:41<00:00, 714.51it/s]\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "OUT_TRAIN = 'train.zip'\n",
    "\n",
    "images_mean = list()\n",
    "images_var = list()\n",
    "\n",
    "with zipfile.ZipFile(OUT_TRAIN, 'w') as img_out:\n",
    "    for idx in tqdm(range(len(images))):\n",
    "        name = img_names[idx]\n",
    "\n",
    "        img = crop_image(images[idx])\n",
    "\n",
    "        images_mean.append((img / 255.0).mean())\n",
    "        images_var.append(((img / 255.0) ** 2).mean()) \n",
    "\n",
    "        img = cv2.imencode('.png', img)[1]\n",
    "        img_out.writestr(name + '.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = crop_image(images[0])\n",
    "# name = img_names[0]\n",
    "# cv2.imwrite(name + '.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.05280547235965753 , std: 0.1628750964925304\n"
     ]
    }
   ],
   "source": [
    "# image stats\n",
    "img_avr =  np.array(images_mean).mean()\n",
    "img_std =  np.sqrt(np.array(images_var).mean() - img_avr**2)\n",
    "print('mean:', img_avr, ', std:', img_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
